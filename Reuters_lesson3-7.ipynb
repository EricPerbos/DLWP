{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.1.0\n",
      "Keras version: 2.0.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "print(\"TensorFlow version: %s\" % tf.__version__)\n",
    "print(\"Keras version: %s\" % keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7.1 The Reuters dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing 3.60 Loading the Reuters dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing 3.61 Taking a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8982"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2246"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing 3.62 Taking a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 245,\n",
       " 273,\n",
       " 207,\n",
       " 156,\n",
       " 53,\n",
       " 74,\n",
       " 160,\n",
       " 26,\n",
       " 14,\n",
       " 46,\n",
       " 296,\n",
       " 26,\n",
       " 39,\n",
       " 74,\n",
       " 2979,\n",
       " 3554,\n",
       " 14,\n",
       " 46,\n",
       " 4689,\n",
       " 4329,\n",
       " 86,\n",
       " 61,\n",
       " 3499,\n",
       " 4795,\n",
       " 14,\n",
       " 61,\n",
       " 451,\n",
       " 4329,\n",
       " 17,\n",
       " 12]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing 3.63 Decoding a newswires back to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "# note that our indices were offset by 3\n",
    "# because 0, 1 and 2 are reserved indices for \"padding\", \"start of sequence\", and \"unknown\".\n",
    "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7.2 Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing 3.65 Encoding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "# our vectorized training data\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# our vectorized test data\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing 3.66 One-hot encoding the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "# our vectorized training labels\n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "# our vectorized test labels\n",
    "one_hot_test_labels = to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing 3.67 One-hot encoding the labels, the Keras way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7.3 Building our network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing 3.68 Our model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing 3.69 Compiling our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7.4 Validating our approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing 3.70 Setting aside a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing 3.71 Training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s - loss: 2.5282 - acc: 0.4907 - val_loss: 1.7156 - val_acc: 0.6190\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 0s - loss: 1.4391 - acc: 0.6934 - val_loss: 1.3379 - val_acc: 0.7130\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 0s - loss: 1.0876 - acc: 0.7652 - val_loss: 1.1626 - val_acc: 0.7440\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 0s - loss: 0.8650 - acc: 0.8171 - val_loss: 1.0785 - val_acc: 0.7590\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 0s - loss: 0.6972 - acc: 0.8490 - val_loss: 0.9808 - val_acc: 0.7820\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 0s - loss: 0.5587 - acc: 0.8800 - val_loss: 0.9363 - val_acc: 0.8010\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 0s - loss: 0.4520 - acc: 0.9070 - val_loss: 0.9081 - val_acc: 0.8040\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 0s - loss: 0.3636 - acc: 0.9231 - val_loss: 0.9383 - val_acc: 0.7920\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 0s - loss: 0.2992 - acc: 0.9327 - val_loss: 0.8853 - val_acc: 0.8100\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 0s - loss: 0.2503 - acc: 0.9419 - val_loss: 0.8996 - val_acc: 0.8150\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 0s - loss: 0.2154 - acc: 0.9483 - val_loss: 0.9175 - val_acc: 0.8130\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 0s - loss: 0.1848 - acc: 0.9503 - val_loss: 0.9064 - val_acc: 0.8160\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 0s - loss: 0.1679 - acc: 0.9530 - val_loss: 0.9297 - val_acc: 0.8110\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 0s - loss: 0.1515 - acc: 0.9562 - val_loss: 0.9584 - val_acc: 0.8060\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 0s - loss: 0.1373 - acc: 0.9554 - val_loss: 0.9685 - val_acc: 0.8160\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 0s - loss: 0.1302 - acc: 0.9559 - val_loss: 1.0201 - val_acc: 0.8040\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 0s - loss: 0.1206 - acc: 0.9577 - val_loss: 1.0233 - val_acc: 0.7990\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 0s - loss: 0.1189 - acc: 0.9575 - val_loss: 1.0426 - val_acc: 0.8030\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 0s - loss: 0.1128 - acc: 0.9594 - val_loss: 1.0955 - val_acc: 0.7970\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 0s - loss: 0.1102 - acc: 0.9599 - val_loss: 1.0755 - val_acc: 0.7990\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "            partial_y_train,\n",
    "            epochs=20,\n",
    "            batch_size=512,\n",
    "            validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing 3.72 Plotting the training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAqEAgCgQCgAAAr/D/XjWLb/UoEoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffa8dc6ae10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo')\n",
    "plt.plot(epochs, val_loss_values, 'b+')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing 3.73 Plotting the training and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffa8dc6ac18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf() # clear figure\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc_values, 'bo')\n",
    "plt.plot(epochs, val_acc_values, 'b+')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing 3.74 Re-training a model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/9\n",
      "8982/8982 [==============================] - 0s - loss: 2.4359 - acc: 0.5363 - val_loss: 1.6416 - val_acc: 0.6500\n",
      "Epoch 2/9\n",
      "8982/8982 [==============================] - 0s - loss: 1.3062 - acc: 0.7196 - val_loss: 1.2993 - val_acc: 0.7075\n",
      "Epoch 3/9\n",
      "8982/8982 [==============================] - 0s - loss: 0.9639 - acc: 0.7892 - val_loss: 1.1402 - val_acc: 0.7498\n",
      "Epoch 4/9\n",
      "8982/8982 [==============================] - 0s - loss: 0.7507 - acc: 0.8407 - val_loss: 1.0338 - val_acc: 0.7694\n",
      "Epoch 5/9\n",
      "8982/8982 [==============================] - 0s - loss: 0.5920 - acc: 0.8762 - val_loss: 0.9827 - val_acc: 0.7805\n",
      "Epoch 6/9\n",
      "8982/8982 [==============================] - 0s - loss: 0.4712 - acc: 0.9012 - val_loss: 0.9727 - val_acc: 0.7872\n",
      "Epoch 7/9\n",
      "8982/8982 [==============================] - 0s - loss: 0.3809 - acc: 0.9183 - val_loss: 0.9517 - val_acc: 0.7903\n",
      "Epoch 8/9\n",
      "8982/8982 [==============================] - 0s - loss: 0.3060 - acc: 0.9353 - val_loss: 0.9607 - val_acc: 0.7956\n",
      "Epoch 9/9\n",
      "8982/8982 [==============================] - 0s - loss: 0.2583 - acc: 0.9413 - val_loss: 0.9763 - val_acc: 0.7921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ffa8dcfff98>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train,\n",
    "            one_hot_train_labels,\n",
    "            epochs=9,\n",
    "            batch_size=512,\n",
    "            validation_data=(x_test, one_hot_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1696/2246 [=====================>........] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing 3.75 Our final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9762544121364346, 0.79207479969688743]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing 3.76 Accuracy of a random baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19723953695458593"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "test_labels_copy = copy.copy(test_labels)\n",
    "np.random.shuffle(test_labels_copy)\n",
    "float(np.sum(np.array(test_labels) == np.array(test_labels_copy))) / len(test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7.5 Generating predictions on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing 3.77 Generating predictions for new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing 3.78 Taking a look at our predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing 3.79 Taking a look at our predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999994"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing 3.80 Taking a look at our predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7.6 A different way to handle the labels and the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing 3.81 Encoding the labels as integer arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing 3.82 Using the sparse_categorical_crossentropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7.7 On the importance of having sufficiently large intermediate layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing 3.83 A model with an information bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/10\n",
      "8982/8982 [==============================] - 0s - loss: 2.5643 - acc: 0.4127 - val_loss: 1.7309 - val_acc: 0.6438\n",
      "Epoch 2/10\n",
      "8982/8982 [==============================] - 0s - loss: 1.3710 - acc: 0.7002 - val_loss: 1.3398 - val_acc: 0.6946\n",
      "Epoch 3/10\n",
      "8982/8982 [==============================] - 0s - loss: 1.0455 - acc: 0.7576 - val_loss: 1.2364 - val_acc: 0.7137\n",
      "Epoch 4/10\n",
      "8982/8982 [==============================] - 0s - loss: 0.8556 - acc: 0.7935 - val_loss: 1.1263 - val_acc: 0.7413\n",
      "Epoch 5/10\n",
      "8982/8982 [==============================] - 0s - loss: 0.7072 - acc: 0.8367 - val_loss: 1.1216 - val_acc: 0.7418\n",
      "Epoch 6/10\n",
      "8982/8982 [==============================] - 0s - loss: 0.5885 - acc: 0.8667 - val_loss: 1.0766 - val_acc: 0.7587\n",
      "Epoch 7/10\n",
      "8982/8982 [==============================] - 0s - loss: 0.4928 - acc: 0.8904 - val_loss: 1.0942 - val_acc: 0.7600\n",
      "Epoch 8/10\n",
      "8982/8982 [==============================] - 0s - loss: 0.4194 - acc: 0.9011 - val_loss: 1.1021 - val_acc: 0.7685\n",
      "Epoch 9/10\n",
      "8982/8982 [==============================] - 0s - loss: 0.3592 - acc: 0.9155 - val_loss: 1.1410 - val_acc: 0.7640\n",
      "Epoch 10/10\n",
      "8982/8982 [==============================] - 0s - loss: 0.3134 - acc: 0.9245 - val_loss: 1.1506 - val_acc: 0.7698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ffa8cd1ffd0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(8, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train,\n",
    "            one_hot_train_labels,\n",
    "            epochs=10,\n",
    "            batch_size=128,\n",
    "            validation_data=(x_test, one_hot_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
